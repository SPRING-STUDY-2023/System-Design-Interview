# 15장. 구글 드라이브 설계

> 구글 드라이브는? 파일 저장 및 동기화 서비스
> 
> - 문서, 사진, 비디오, 기타 파일을 클라우드에 보관
> - 어떤 단말에서든 이용 가능
> - 보관된 파일을 다른 사람들과 손쉽게 공유 가능

## 1단계 문제 이해 및 설계 범위 확정

### 요구사항 파악

- `지원 기능`
    - 파일 업로드/다운로드
    - 파일 동기화
    - 알림(notification)
- `지원 디바이스`
    - 모바일 앱
    - 웹 앱
- `파일 암호화` : O
- `파일 크기 제한` : 최대 10GB
- `사용자 수` : DAU 천만 명

### 요구사항 정리

**[기능적 요구사항]**

1. 파일 추가 - ex. 파일을 구글 드라이브 안으로 떨구는(drag-and-drop) 것 
2. 파일 다운로드
3. 여러 단말에 파일 동기화
4. 파일 갱신 이력 조회(revision history)
5. 파일 공유
6. 파일 편집/삭제/공유 시 알림 표시
7. ~~Google Docs 편집 및 협업 기능 (동시 편집 기능)~~
    
    → 이번 챕터에서는 고려 대상 X
    

**[비기능적 요구사항]**

1. 안정성 : 데이터 손실이 발생해서는 안 됨 in 데이터 저장소
2. 빠른 동기화 속도 : 파일 동기화에 너무 많은 시간이 걸리지 않아야 사용자가 이탈하지 않음
3. 네트워크 대역폭 : 불필요한 대역폭 소모 최소화 (*특히 모바일 데이터 플랜 사용 시 주의)
4. 규모 확장성 : 대용량 트래픽 처리가 가능해야 함
5. 높은 가용성 : 시스템은 항상 사용 가능해야 함

### 개략적 추정치

- 가입 사용자는 5천만 명, DAU 사용자는 1천만 명이 있다고 가정
- 모든 사용자에게 10GB의 무료 저장공간 할당
- 매일 각 사용자가 평균 2개의 파일을 업로드한다고 가정 → 각 파일의 평균 크기 : 500KB
- **읽기 : 쓰기**의 비율은 1:1

**⇒ [정리]**

> 필요한 저장공간 총량 = 5천만 사용자 X 10GB = 500PB
> 
> 
> 업로드 API QPS = 1천만 사용자 X 2회 업로드/24시간/3600초 = 약 240
> 
> 최대 QPS = QPS X 2 = 480
> 

## 2단계 개략적 설계안 제시 및 동의 구하기

<aside>
💡 접근 방식

1대의 서버에 모든 것을 담고 → 점진적으로 천만 사용자 지원이 가능한 시스템으로 발전시켜 나가기

</aside>

### *서버 1대에 모두 구성한다면?*

- 파일을 올리고 다운로드 하는 과정을 처리할 웹 서버
- 사용자 데이터, 로그인 정보, 파일 정보 등의 메타데이터를 보관할 데이터베이스
- 파일을 저장할 저장소 시스템 → 파일 저장을 위해 1TB의 공간을 사용

<aside>
📎 Spec

- Apache 웹 서버
- MySQL 데이터베이스
- `drive/` 디렉터리 - 업로드되는 파일 저장 용도
    - `네임스페이스`라는 하위 디렉터리들
    - 특정 사용자가 올린 파일이 원본명 그대로 보관됨
    
    ⇒ 각 파일과 폴더는 상대 경로 + 네임스페이스의 결합으로 식별이 가능함
    
</aside>

### API (3가지)

*default - 사용자 인증 필요, HTTPS (SSL 지원) 프로토콜 사용 

1. 파일 업로드 API
    - 단순 업로드 : 파일 크기 小
    - 이어 올리기 (resumable upload) : 파일 크기 大, 네트워크 문제로 업로드가 중단될 가능성이 높을 때 사용
        
        *ex. `https://api.example.com/files/upload?uploadType=resumable`*
        
        [인자]
        
        - uploadType=resumable
        - data : 업로드할 로컬 파일
        
        [절차]
        
        1. 이어 올리기 URL을 받기 위한 최초 요청 전송
        2. 데이터를 업로드하고 업로드 상태 모니터링
        3. 업로드에 장애가 발생하면 장애 발생시점부터 업로드를 재시작
    
2. 파일 다운로드 API
    
    *ex. `https://api.example.com/files/download`*
    
    [인자]
    
    - path : 다운로드할 파일의 경로
        
        ```sql
        {
        		"path": "/recipes/soup/best_soup.txt"
        }
        ```
        
    
3. 파일 갱신 히스토리 제공 API
    
    *ex. `https://api.example.com/files/list_revisions`* 
    
    [인자]
    
    - path : 갱신 히스토리를 가져올 파일의 경로
    - limit : 히스토리 길이의 최대치
        
        ```sql
        {
        		"path": "/recipes/soup/best_soup.txt",
        		"limit": 20
        }
        ```
        

### 1대의 서버를 사용하는 제약을 극복해야 한다 ..

업로드 되는 파일의 수가 많아질수록 파일 시스템 역시 가득 차게 될 것이다. 여유 공간이 얼마 없으면 사용자가 더 이상 파일을 올릴 수 없게 되는 문제가 발생한다. 

1. 샤딩 (sharding) : 데이터를 여러 서버에 나누어 저장하기
2. Amazon S3 사용 : 넷플릭스, 에어비앤비 등에서도 저장소로 사용하는 서비스로, 업계 최고 수준의 규모 확장성, 가용성, 보안, 성능을 제공하는 객체 저장소 서비스 ✅

> S3 서비스의 다중화를 이용하자!
> 

AWS Region = 데이터 센터를 운영하는 지리적 영역 / S3 버킷 = 파일 시스템의 폴더와 유사

- 설정한 리전으로부터 같은 지역 안에서만 or 여러 지역에 걸쳐 다중화를 할 수 있다

[추가로 고려할 내용]

- 로드밸런서 : 네트워크 트래픽을 고르게 분산하기 위함 → 특정 웹 서버에 장애가 발생하면 자동으로 우회
- 웹 서버 : 로드밸런서를 추가하면 웹 서버를 쉽게 추가할 수 있음 → 트래픽 폭증에 대응 가능
- 메타데이터 데이터베이스 : DB를 파일 저장 서버에서 분리함으로써 SPOP 회피 가능
- 파일 저장소 : S3를 파일 저장소로 사용하고, 가용성과 데이터 무손실을 보장하기 위해 2개 이상의 지역에 데이터를 다중화함

### 동기화 충돌

2명 이상의 사용자가 동시에 같은 파일/폴더를 업데이트하려고 할 때, 충돌이 발생한다면?

> 먼저 처리되는 변경은 성공한 것으로, 나중에 처리되는 변경은 충돌이 발생한 것으로 표시
> 

→ 오류 발생 시점에서 같은 파일의 2가지 버전이 존재하게 되는데, 사용자는 이 두 파일을 하나로 합칠지, 둘 중 하나를 다른 파일로 대체할지를 결정해야 한다

### 개략적 설계안

![Untitled](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/f68e9cd0-dc49-4be2-8e5f-fc61e62817fc)

- `사용자 단말` : 웹 브라우저, 모바일 앱 등의 클라이언트
- `블록 저장소 서버` : 파일 블록을 클라우드 저장소에 업로드하는 서버 (block server, blocked-level storage)
    
    → 클라우드 환경에서 데이터 파일을 저장하는 기술
    
    - 파일을 여러 개의 블록으로 나누어 저장
    - 각 블록은 고유한 해시값 할당 & 독립적인 객체로 취급
        
        *최대 4MB로 설정
        
- `클라우드 저장소` : 파일이 블록 단위로 나누어 클라우드 저장소에 보관됨
- `아카이빙 저장소` : 오랫동안 사용되지 않은 비활성 데이터를 저장히기 위한 컴퓨터 시스템 (cold storage)
- `로드밸런서` : 요청을 모든 API 서버에 고르게 분산하는 구실
- `API 서버` : 파일 업로드 외에 거의 모든 것(사용자 인증, 사용자 프로파일 관리, 파일 메타데이터 갱신 등)을 담당하는 서버
- `메타데이터 데이터베이스` : 사용자, 파일, 블록, 버전 등의 메타데이터 정보 관리
- `메타데이터 캐시` : 자주 사용되는 메타데이터 보관 → 성능을 높이기 위함
- `알림 서비스` : 특정 이벤트가 발생했음을 알리는 데 쓰이는 발생/구독 프로토콜 기반 시스템
- `오프라인 사용자 백업 큐` : 클라이언트가 접속 중이 아니라서 파일의 최신 상태를 확인할 수 없을 때 해당 정보를 이 큐에 보관 → 클라이언트가 나중에 접속했을 때 동기화되도록 함

## 3단계 상세 설계

### 블록 저장소 서버

> 파일 업로드에 관한 힘든 일을 처리하는 컴포넌트
> 
> 
> → 파일 블록 단위의 분할, 각 블록에 압축 알고리즘 적용, 암호화, 수정된 블록만 전송 등
> 

![새 파일이 추가되었을 때의 동작](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/f1d12c7f-ed2a-4655-891c-06559fe5195e)

새 파일이 추가되었을 때의 동작

1. 주어진 파일을 작은 블록들로 분할
2. 각 블록을 압축
3. 클라우드 저장소로 보내기 전에 암호화
4. 클라우드 저장소로 전송

정기적으로 갱신되는 큰 파일들은 업데이트 시마다 전체 파일을 서버로 보내면 **네트워크 대역폭**을 많이 잡아먹게 된다. 

→ 이를 최적화하기 위한 방안

1. 델타 동기화 (delta sync) : 파일이 수정되면 전체 파일 대신 수정이 일어난 블록만 동기화하는 것
2. 압축 (compression) : 블록 단위로 압축해두면 데이터 크기를 많이 줄일 수 있는데, 이때 압축 알고리즘은 파일 유형에 따라 결정됨
    
    ex. 텍스트 파일 압축 - gzip, bzip2  (이미지/비디오 압축은 다른 알고리즘으로!)
    

![델타 동기화 전략의 동작 (검정색 블록 = 수정된 블록)](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/660d067e-767e-4010-a51d-4889859d96ec)

델타 동기화 전략의 동작 (검정색 블록 = 수정된 블록)

위와 같이 갱신된 부분만 동기화해야 하므로, 2개 블록만 클라우드 저장소에 업로드하게 된다.

### 높은 일관성 요구사항

> 강한 일관성 모델을 기본으로 지원해야 한다 ⇒ 같은 파일이 단말/사용자에 따라 다르게 보여서는 안 된다.
> 
- 메타데이터 캐시
- 데이터베이스 계층

위 모두에 일관성의 원칙이 적용되어야 하므로, 이를 달성하기 위해 메모리 캐시에서는 **최종 일관성 모델**을 지원한다. 

1. 캐시에 보관된 사본과 데이터베이스의 원본(master)이 일치한다
2. 데이터베이스에 보관된 원본에 변경이 발생하면 캐시에 있는 사본을 무효화한다

*본 설계안에서는 NoSQL이 아닌, ACID를 보장하는 관계형 DB를 채택한다.

### 메타데이터 데이터베이스

![Untitled](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/b6eb0cab-3d46-4c44-a02e-b0dcf23b7a5c)

- `namespace` : 사용자의 루트 디렉터리 정보
- `file` : 파일의 최신 정보
- `file_version` : 파일의 갱신 이력 (read-only)
- block

### 업로드 절차

![Untitled](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/6a3f9582-241c-47c3-95ee-98378c213259)

> *사용자가 파일을 업로드하면 무슨 일이 벌어질까?*
> 
- 파일 메타데이터 추가
    1. 클라이언트1이 새 파일의 메타데이터를 추가하기 위한 요청 전송
    2. 새 파일의 메타데이터를 데이터베이스에 저장하고 업로드 상태를 대기중(pending)으로 변경
    3. 새 파일이 추가되었음을 알림 서비스에 통지
    4. 알림 서비스는 관련된 클라이언트2에게 파일이 업로드되고 있음을 알림

- 파일을 클라우드 저장소에 업로드
    
    2.1 클라이언트1이 파일을 블록 저장소 서버에 업로드
    
    2.2 블록 저장소 서버는 파일을 블록 단위로 쪼갠 다음 압축하고 암호화 한 후, 클라우드 저장소에 전송
    
    2.3 업로드가 끝나면 클라우드 스토리지는 완료 콜백을 호출, 이 콜백 호출은 API 서버로 전송됨
    
    2.4 메타데이터 DB에 기록된 해당 파일의 상태를 완료(uploaded)로 변경
    
    2.5 알림 서비스에 파일 업로드가 끝났음을 통지
    
    2.6 알림 서비스는 관련된 클라이언트2에게 파일 업로드가 끝났음을 알림
    

### 다운로드 절차

> 파일이 새로 추가되거나 편집되면 자동으로 시작
> 
> 
> → *클라이언트는 다른 클라이언트의 편집/추가를 어떻게 감지할 수 있을까?*
> 

![Untitled](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/27c91592-8be5-41a3-a7c4-098dd77f8e3e)

1. 알림 서비스가 클라이언트2에게 누군가 파일을 변경했음을 알림
2. 알림을 확인한 클라이언트2는 새로운 메타데이터를 요청
3. API 서버는 메타데이터 데이터베이스에게 새 메타데이터 요청
4. API 서버에게 새 메타데이터가 반환됨
5. 클라이언트2에게 새 메타데이터가 반환됨
6. 클라이언트2는 새 메타데이터를 받는 즉시 블록 다운로드 요청 전송
7. 블록 저장소 서버는 클라우드 저장소에서 블록 다운로드
8. 클라우드 저장소는 블록 서버에 요청된 블록 반환
9. 블록 저장소 서버는 클라이언트에게 요청된 블록 반환, 클라이언트2는 전송된 블록을 사용하여 파일 재구성

### 알림 서비스

채팅 서비스와 달리, 양방향 통신이 필요하지 않고 알림을 보낼 일이 자주 발생하는 게 아니므로 웹소켓 보다 롱 폴링이 더 적합하다!

- 각 클라이언트는 알림 서버와 롱 폴링용 연결을 유지하다가 특정 파일에 대한 변경을 감지하면 해당 연결을 끊는다
- 클라이언트는 이때 반드시 메타데이터 서버와 연결해 파일의 최신 내역을 다운로드 해야 하고, 해당 다운로드 작업이 끝났거나 연결 타임아웃 시간을 도달한 경우, 즉시 새 요청을 보내서 롱 폴링 연결을 복원하고 유지해야 한다

### 파일 저장소 공간 절약

> 파일의 갱신 이력 보존 및 안정성을 보장하기 위해 파일의 여러 버전을 관리할 필요가 있다
> 

버전 관리에 의해 저장 용량이 너무 빨리 소진되는 것을 막고, 비용을 절감하기 위해서는?

1. 중복 제거(de-dupe) : 중복된 파일 블록을 계정 차원에서 제거하는 방법
    
    → 해시 값으로 같은 블록인지 판단
    
2. 지능적 백업 전략 도입 
    - 한도 설정 : 보관해야 할 파일의 버전 개수 상한 지정
    - 중요한 버전만 보관 : 자주 바뀌는 파일에 대해, 모든 버전이 필요한 것은 아니므로 불필요한 버전과 사본이 만들어지는 것을 방지해야 함
3. 자주 쓰이지 않는 데이터 ⇒ 아카이빙 저장소로 이동
    - 몇 달 or 수년간 이용되지 않은 데이터
    - Amazon S3 Glacier

### 장애 처리 흐름

- 로드밸런서 장애 - 부 로드밸런서가 활성화되어 트래픽을 이어받도록 함
- 블록 저장소 서버 장애 - 다른 서버가 미완료 / 대기 상태인 작업을 이어받도록 함
- 클라우드 저장소 장애 - S3 버킷 다중화 ⇒ 다른 지역에서 파일 가져오기
- API 서버 장애 - 로드밸런서에 의해 처리 (stateless이기 때문에 가능)
- 메타데이터 캐시 장애 - 다중화 ⇒ 한 노드에 장애가 발생하면 다른 노드에서 데이터를 가져옴 & 장애 서버는 교체
- 메타데이터 데이터베이스 장애
    - 주 데이터베이스 서버 장애
    - 부 데이터베이스 서버 장애
- 알림 서비스 장애 - 한 대 서버에 장애가 발생하면 백만 명 이상의 사용자가 롱 폴링 연결을 다시 만들어야 함 (접속 중인 모든 사용자가 알림 서버-롱 폴링 연결을 하나씩 유지하므로)
- 오프라인 사용자 백업 큐 장애 - 큐에 장애가 발생하면 구독 중인 클라이언트 백업 큐로 구독 관계 재설정

## 4단계 마무리

해당 설계안 외에 다른 선택지도 고려해보면 좋다!

> 블록 저장소 서버를 거치지 않고 파일을 클라우드 저장소에 직접 업로드한다면?
> 
- 장점 - 업로드 시간 단축
- 단점
    - 분할, 압축, 암호화 로직을 클라이언트에 두어야 하므로, 플랫폼별로 따로 구현해야 한다(iOS, Android, Web)
    - 클라이언트가 해킹당할 가능성이 있으므로 암호화 로직을 클라이언트 안에 두는 건 적절하지 X

> 접속상태 관리 로직을 별도의 서비스로 옮긴다면?
> 

알림 서비스로부터 관련 로직을 분리한다면 다른 서비스에서도 쉽게 활용할 수 있을 것!
